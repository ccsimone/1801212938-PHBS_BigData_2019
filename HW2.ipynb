{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimate of Theta of climate_change_1 is \n",
      " [[-1.24594261e+02]\n",
      " [ 6.42053134e-02]\n",
      " [ 6.45735927e-03]\n",
      " [ 1.24041896e-04]\n",
      " [-1.65280033e-02]\n",
      " [-6.63048890e-03]\n",
      " [ 3.80810325e-03]\n",
      " [ 9.31410842e-02]\n",
      " [-1.53761324e+00]] \n",
      "-----------\n",
      "The estimate of Theta of climate_change_2 is \n",
      " [[-1.31233611e+02]\n",
      " [ 6.42053134e-02]\n",
      " [ 6.45735927e-03]\n",
      " [-6.49209352e-03]\n",
      " [-1.65280032e-02]\n",
      " [-6.63048889e-03]\n",
      " [ 3.80810324e-03]\n",
      " [ 9.31410837e-02]\n",
      " [-1.53761324e+00]\n",
      " [ 6.60761527e+00]] \n",
      "-----------\n",
      "R square of train set 1 is 0.750893277187922\n",
      "R square of test set 1 is 0.21622556651959746\n",
      "R square of train set 2 is 0.7207151931204864\n",
      "R square of test set 2 is 0.22956694401085823\n",
      "-----------\n",
      "For climate_change_1: \n",
      " t value is: \n",
      " [-6.26517397  9.92322601  2.8264197   0.2404694  -1.92972605 -4.07783388\n",
      "  3.75729271  6.31256096 -7.21030085] \n",
      " p value is: \n",
      " [1.43104610e-09 4.89888644e-20 5.05252061e-03 8.10145552e-01\n",
      " 5.46693113e-02 5.95728750e-05 2.09719895e-04 1.09594440e-09\n",
      " 5.41127295e-12] \n",
      " rank is: \n",
      " 9 \n",
      "-----------\n",
      "For climate_change_2: \n",
      " t value is: \n",
      " [-1.10508247e-03  8.80063418e+00  2.50667332e+00 -5.46681509e-05\n",
      " -1.71142055e+00 -3.61651787e+00  3.33223879e+00  5.59843539e+00\n",
      " -6.39461603e+00  5.56409280e-05] \n",
      " p value is: \n",
      " [9.99119076e-01 1.56318877e-16 1.27667836e-02 9.99956421e-01\n",
      " 8.81351398e-02 3.55357589e-04 9.80016190e-04 5.24999877e-08\n",
      " 6.91531770e-10 9.99955645e-01] \n",
      " rank is: \n",
      " 9 \n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "df1 = pd.read_csv('climate_change_1.txt')\n",
    "df2 = pd.read_csv('climate_change_2.txt')\n",
    "\n",
    "# split the data into training data and test data\n",
    "data_split = 2006\n",
    "df1_train = df1[df1['Year'] <= data_split]\n",
    "df1_test = df1[df1['Year'] > data_split]\n",
    "df2_train = df2[df2['Year'] <= data_split]\n",
    "df2_test = df2[df2['Year'] > data_split]\n",
    "\n",
    "\n",
    "# distingush the data as label\n",
    "df1_train_temp = df1_train['Temp']\n",
    "df1_test_temp = df1_test['Temp']\n",
    "df2_train_temp = df2_train['Temp']\n",
    "df2_test_temp = df2_test['Temp']\n",
    "length_train1 = len(df1_train_temp)\n",
    "length_test1 = len(df1_test_temp)\n",
    "length_train2 = len(df2_train_temp)\n",
    "length_test2 = len(df2_test_temp)\n",
    "\n",
    "\n",
    "# distingush the data as feature\n",
    "df1_train_x = (df1_train.loc[:,'MEI':'Aerosols'])\n",
    "df1_train_x.insert(0, 'theta0', np.ones(length_train1))\n",
    "df1_test_x = df1_test.loc[:,'MEI':'Aerosols']\n",
    "df1_test_x.insert(0, 'theta0', np.ones(length_test1))\n",
    "\n",
    "df2_train_x = df2_train.loc[:,'MEI':'NO']\n",
    "df2_train_x.insert(0, 'theta0', np.ones(length_train2))\n",
    "df2_test_x = df2_test.loc[:,'MEI':'NO']\n",
    "df2_test_x.insert(0, 'theta0', np.ones(length_test2))\n",
    "\n",
    "\n",
    "#function closed_form_1()\n",
    "def closed_form_1(x,y):\n",
    "    xTx = mat(x).T @ mat(x)\n",
    "    xTy = mat(x).T @ mat(y).T\n",
    "    if linalg.det(xTx) == 0.0:\n",
    "        print(\"This matrix is singular, cannot do inverse\")\n",
    "        return\n",
    "    return xTx.I @ xTy\n",
    "\n",
    "\n",
    "theta1 = closed_form_1(df1_train_x, df1_train_temp)\n",
    "print(\"The estimate of Theta of climate_change_1 is \\n\", theta1, \"\\n-----------\")\n",
    "theta2 = closed_form_1(df2_train_x, df2_train_temp)\n",
    "print(\"The estimate of Theta of climate_change_2 is \\n\", theta2, \"\\n-----------\")\n",
    "\n",
    "\n",
    "# y = ax + b and in this case y = x @ theta \n",
    "#function to calculate R square\n",
    "def R_2(x, y, theta_):\n",
    "    n = len(y)\n",
    "    f = reshape(np.array(mat(x) @ theta_), n)\n",
    "    y = np.array(y)\n",
    "    y_ = np.ones(n) * sum(y) / n\n",
    "    ssr = sum((f - y_) ** 2)\n",
    "    sse = sum((y - f) ** 2)\n",
    "    sst = ssr + sse\n",
    "    return ssr/sst\n",
    "\n",
    "\n",
    "R_2_train1 = R_2(df1_train_x, df1_train_temp, theta1)\n",
    "R_2_test1 = R_2(df1_test_x, df1_test_temp, theta1)\n",
    "print(\"R square of train set 1 is\", R_2_train1)\n",
    "print(\"R square of test set 1 is\", R_2_test1)\n",
    "\n",
    "R_2_train2 = R_2(df2_train_x, df2_train_temp, theta2)\n",
    "R_2_test2 = R_2(df2_test_x, df2_test_temp, theta2)\n",
    "print(\"R square of train set 2 is\", R_2_train2)\n",
    "print(\"R square of test set 2 is\", R_2_test2)\n",
    "print(\"-----------\")\n",
    "\n",
    "# write a t-test to do the significance test\n",
    "def t_test(x,y,theta_,p):\n",
    "    n = len(y)\n",
    "    f = reshape(np.array(mat(x) @ theta_),n)\n",
    "    y = np.array(y)\n",
    "    xTx = mat(x).T @ mat(x)\n",
    "    #a, b = np.linalg.eig(xTx) # k = max(a) / min(a)\n",
    "    xTxI = xTx.I\n",
    "    xTxI = np.array(xTxI)\n",
    "    p1=p+1\n",
    "    c=np.zeros(p1)\n",
    "    for jj in range(p1):\n",
    "        c[jj] = xTxI[jj][jj]\n",
    "    sse = sum((y - f) ** 2)\n",
    "    sigma_h = sqrt(sse/(n-p1))\n",
    "    t = np.zeros(p1)\n",
    "    pv = np.zeros(p1)\n",
    "    pv1 = np.zeros(p1)\n",
    "    for i in range(p1):\n",
    "        t[i] = theta_[i] / sigma_h / sqrt(c[i])\n",
    "        pv[i] = 2 *(stats.t.sf(np.abs(t[i]),n-p1)) \n",
    "        #pv1[i]= 2*(1-stats.t.cdf(np.abs(t[i]),n-p1)) #just make a validation, it means the same with the last line\n",
    "        #The former mistake is from the absolute of t value\n",
    "    return t, pv, np.linalg.matrix_rank(xTx) #pv1\n",
    "\n",
    "test1 = t_test(df1_train_x, df1_train_temp,theta1,8)\n",
    "print(\"For climate_change_1: \\n\", \"t value is: \\n\", test1[0], \"\\n p value is: \\n\", test1[1], \"\\n rank is: \\n\",test1[2],\"\\n-----------\")\n",
    "test2 = t_test(df2_train_x, df2_train_temp,theta2,9)\n",
    "print(\"For climate_change_2: \\n\", \"t value is: \\n\", test2[0], \"\\n p value is: \\n\", test2[1], \"\\n rank is: \\n\",test2[2],\"\\n-----------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1 question 2:\n",
    "    \n",
    "   The function is： y = ax + b and in this case y = x @ theta "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1 question 3:\n",
    "\n",
    "    1,2,5,6,7,8 are both significant, they are MEI,CO2,CFC-11,CFC-12,TSI,Aerosols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1 question 4:\n",
    "\n",
    "    For climate_change_2: The p value of the last parameter is larger than 0.05, so we cannot reject the null hypothesis. The consequene is that we cannot use the closed_form_1, and it results from the multicollinearity.\n",
    "        There are two necessary conditions and one less important condition:\n",
    "        1.XTX is inversible, i.e. the det of XTX is not equal to zero.\n",
    "        2.The rank of matrix XTX should equal to p+1. where p is the parameter in model. In that case, the climate_change_2 data has a rank 9 which is smaller that p+1=10, so there exists multicollinearity.\n",
    "        3.An important index to measure the severity of multicollinearity, the condition number k of xTx. k (XTX) is the ratio of the maximum eigenvalue to the minimum eigenvalue of the square matrix XTX. The condition number characterizes the difference in the eigenvalues of XTX. K <100 indicates that the degree of multicollinearity is small, 100 <k <1000 indicates that there is a medium layer or strong multicollinearity, and k> 1000 indicates that a serious Multicollinearity. But that condition is not necessary.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2 question 1：**\n",
    "* The loss function with $L_1$ regularization $$(Y-X\\beta)'(Y-X\\beta)+\\alpha e'|\\beta|$$\n",
    "* The loss function with $L_2$ regularization $$(Y-X\\beta)'(Y-X\\beta)+\\lambda \\beta'\\beta$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The regulation estimate of Theta of climate_change_1 is \n",
      " [[-0.0007483 ]\n",
      " [ 0.04227705]\n",
      " [ 0.0082121 ]\n",
      " [ 0.00022362]\n",
      " [-0.01703597]\n",
      " [-0.00649697]\n",
      " [ 0.00376607]\n",
      " [ 0.00143887]\n",
      " [-0.07876751]] \n",
      "-----------\n",
      "The regulation estimate of Theta of climate_change_2 is \n",
      " [[-0.0007483 ]\n",
      " [ 0.04227709]\n",
      " [ 0.0082121 ]\n",
      " [ 0.00022437]\n",
      " [-0.01703599]\n",
      " [-0.00649698]\n",
      " [ 0.00376607]\n",
      " [ 0.00143943]\n",
      " [-0.07876759]\n",
      " [-0.00074807]] \n",
      "-----------\n",
      "R square of regulation train set 1 is 0.6815401104630927\n",
      "R square of regulation test set 1 is 0.3519412583261267\n",
      "R square of regulation train set 2 is 0.6815403606936618\n",
      "R square of regulation test set 2 is 0.3519407955746182\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "def closed_form_2(x, y, lamda):\n",
    "    I = np.identity(x.shape[1])\n",
    "    xTx1 = mat(x).T @ mat(x) + lamda * I\n",
    "    xTy = mat(x).T @ mat(y).T\n",
    "    return xTx1.I @ xTy\n",
    "\n",
    "theta1_r = closed_form_2(df1_train_x, df1_train_temp,3)\n",
    "print(\"The regulation estimate of Theta of climate_change_1 is \\n\", theta1_r, \"\\n-----------\")\n",
    "theta2_r = closed_form_2(df2_train_x, df2_train_temp,3)\n",
    "print(\"The regulation estimate of Theta of climate_change_2 is \\n\", theta2_r, \"\\n-----------\")\n",
    "\n",
    "R_2_train1_r = R_2(df1_train_x, df1_train_temp, theta1_r)\n",
    "R_2_test1_r = R_2(df1_test_x, df1_test_temp, theta1_r)\n",
    "print(\"R square of regulation train set 1 is\", R_2_train1_r)\n",
    "print(\"R square of regulation test set 1 is\", R_2_test1_r)\n",
    "\n",
    "R_2_train2_r = R_2(df2_train_x, df2_train_temp, theta2_r)\n",
    "R_2_test2_r = R_2(df2_test_x, df2_test_temp, theta2_r)\n",
    "print(\"R square of regulation train set 2 is\", R_2_train2_r)\n",
    "print(\"R square of regulation test set 2 is\", R_2_test2_r)\n",
    "print(\"-----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2 question 3：\n",
    "\n",
    "R square of train set 1 is 0.750893277187922\n",
    "\n",
    "R square of test set 1 is 0.21622556651959746\n",
    "\n",
    "R square of regulation train set 1 is 0.6815401104630927\n",
    "\n",
    "R square of regulation test set 1 is 0.3519412583261267\n",
    "    \n",
    "   We can discover that the R square on test data of regulation set is higher than original data. It means that the regulation one is more robust.\n",
    "   The reason is that the L2 loss is calculated from the residuals. Because the residual between the fitted line and the noise is relatively large, and the L2 loss is considered on the basis of this squared, so the L2 loss will be larger.\n",
    "    This effect is that the fitting straight line we use will \"value\" the noise points more, and the whole fitting straight line will be biased towards the noise point, so it is more stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R square of regulation train set 1 is [0.67662539 0.67749056 0.67851892 0.68653222 0.70616438 0.71432621\n",
      " 0.71624189]\n",
      "R square of regulation test set 1 is [0.3584209  0.35704197 0.35544352 0.34803822 0.33078523 0.31986819\n",
      " 0.31627807]\n",
      "R square of regulation train set 2 is [0.67662543 0.67749061 0.67851899 0.68653302 0.7061743  0.71443265\n",
      " 0.71724332]\n",
      "R square of regulation test set 2 is [0.35842085 0.35704189 0.35544339 0.34803673 0.33076615 0.3196537\n",
      " 0.31419039]\n"
     ]
    }
   ],
   "source": [
    "lamda_list=np.array([20, 15, 10, 1, 0.1, 0.01, 0.001])\n",
    "R2_1_train = np.zeros(7)\n",
    "R2_1_test = np.zeros(7)\n",
    "R2_2_train = np.zeros(7)\n",
    "R2_2_test = np.zeros(7)\n",
    "    \n",
    "for i in range(7):\n",
    "    lam = lamda_list[i]\n",
    "\n",
    "    #print(\"************************************************\")\n",
    "    #print(\"when lambda is:\",i)\n",
    "    theta1_r = closed_form_2(df1_train_x, df1_train_temp,lam)\n",
    "    #print(\"The regulation estimate of Theta of climate_change_1 is \\n\", theta1_r, \"\\n-----------\")\n",
    "    theta2_r = closed_form_2(df2_train_x, df2_train_temp,lam)\n",
    "    #print(\"The regulation estimate of Theta of climate_change_2 is \\n\", theta2_r, \"\\n-----------\")\n",
    "\n",
    "    R2_1_train[i] = R_2(df1_train_x, df1_train_temp, theta1_r)\n",
    "    R2_1_test[i] = R_2(df1_test_x, df1_test_temp, theta1_r)\n",
    "    #print(\"R square of regulation train set 1 is\", R2_1_train[i])\n",
    "    #print(\"R square of regulation test set 1 is\", R2_1_test[i])\n",
    "\n",
    "    R2_2_train[i] = R_2(df2_train_x, df2_train_temp, theta2_r)\n",
    "    R2_2_test[i] = R_2(df2_test_x, df2_test_temp, theta2_r)\n",
    "    #print(\"R square of regulation train set 2 is\", R2_2_train[i])\n",
    "    #print(\"R square of regulation test set 2 is\", R2_2_test[i])\n",
    "    #print(\"-----------\")\n",
    "\n",
    "print(\"R square of regulation train set 1 is\", R2_1_train)\n",
    "print(\"R square of regulation test set 1 is\", R2_1_test)\n",
    "print(\"R square of regulation train set 2 is\", R2_2_train)\n",
    "print(\"R square of regulation test set 2 is\", R2_2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Square of value')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "lamda_list=np.array([20, 15, 10, 1, 0.1, 0.01, 0.001])\n",
    "x_values = list(range(1,8))\n",
    "y1_values = R2_1_train\n",
    "y2_values = R2_1_test\n",
    "y3_values = R2_2_train\n",
    "y4_values = R2_2_test\n",
    "plt.scatter(x_values, y1_values, edgecolor='none', s=100, marker='|')\n",
    "plt.scatter(x_values, y2_values, edgecolor='none', s=100, marker='|')\n",
    "plt.scatter(x_values, y3_values, edgecolor='none', s=100, marker='*')\n",
    "plt.scatter(x_values, y4_values, edgecolor='none', s=100, marker='*')\n",
    "\n",
    "plt.title(\"R square\", fontsize=24)\n",
    "plt.xlabel(\"Value\", fontsize=14)\n",
    "plt.ylabel(\"Square of value\", fontsize=14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2 question 4:\n",
    "\n",
    "Each lambda corresponds to a set of weights. As the lambda increases, the weight gradually decreases. The best parameters are in one of these groups. To quantitatively find the best parameters, cross-validation is also required. \n",
    "\n",
    "Print the R square graph, we can se that when lambda=10, it has a larger R square than the lambda<10. And when the lambda>10, the result becomes stable, so to make a better trade off, we select the lamda=10.\n",
    "\n",
    "The importance of cross validation: We do not have sufficient to do the tests. So in a given modeling sample, take out most of the samples to build a model, leave a small part of the sample to forecast using the model just established, and find the forecast error of this small sample, and record their sum of squares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 3 question 1:\n",
    "Steps in stepwise regression analysis:\n",
    "1. For all factors, the regression equation is introduced one by one according to the degree of its influence on y (partial regression squared)\n",
    "2. Test all the variables contained in the regression equation at any time to see if they are still significant;\n",
    "3. Among the remaining unselected factors, select the one that has the greatest effect on y and test its significance;\n",
    "4. Significant, the equation is introduced, and not significant, the equation is not introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:49: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  data_klasses = (pandas.Series, pandas.DataFrame, pandas.Panel)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Temp</td>       <th>  R-squared:         </th> <td>   0.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   17.04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 22 Dec 2019</td> <th>  Prob (F-statistic):</th> <td>1.06e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:43:14</td>     <th>  Log-Likelihood:    </th> <td> -29.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   284</td>      <th>  AIC:               </th> <td>   69.07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   279</td>      <th>  BIC:               </th> <td>   87.32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>   -0.0016</td> <td>    0.000</td> <td>   -7.778</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>   -0.0041</td> <td>    0.001</td> <td>   -3.520</td> <td> 0.001</td> <td>   -0.006</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>    0.0054</td> <td>    0.002</td> <td>    2.585</td> <td> 0.010</td> <td>    0.001</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th> <td>   -0.0034</td> <td>    0.007</td> <td>   -0.510</td> <td> 0.611</td> <td>   -0.016</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th> <td>    0.0406</td> <td>    0.018</td> <td>    2.314</td> <td> 0.021</td> <td>    0.006</td> <td>    0.075</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 5.383</td> <th>  Durbin-Watson:     </th> <td>   0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.068</td> <th>  Jarque-Bera (JB):  </th> <td>   5.851</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.206</td> <th>  Prob(JB):          </th> <td>  0.0536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.570</td> <th>  Cond. No.          </th> <td>    83.7</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   Temp   R-squared:                       0.234\n",
       "Model:                            OLS   Adj. R-squared:                  0.220\n",
       "Method:                 Least Squares   F-statistic:                     17.04\n",
       "Date:                Sun, 22 Dec 2019   Prob (F-statistic):           1.06e-14\n",
       "Time:                        15:43:14   Log-Likelihood:                -29.537\n",
       "No. Observations:                 284   AIC:                             69.07\n",
       "Df Residuals:                     279   BIC:                             87.32\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.0016      0.000     -7.778      0.000      -0.002      -0.001\n",
       "x2            -0.0041      0.001     -3.520      0.001      -0.006      -0.002\n",
       "x3             0.0054      0.002      2.585      0.010       0.001       0.010\n",
       "x4            -0.0034      0.007     -0.510      0.611      -0.016       0.010\n",
       "x5             0.0406      0.018      2.314      0.021       0.006       0.075\n",
       "==============================================================================\n",
       "Omnibus:                        5.383   Durbin-Watson:                   0.099\n",
       "Prob(Omnibus):                  0.068   Jarque-Bera (JB):                5.851\n",
       "Skew:                           0.206   Prob(JB):                       0.0536\n",
       "Kurtosis:                       3.570   Cond. No.                         83.7\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "df1 = pd.read_csv('climate_change_1.txt')\n",
    "df2 = pd.read_csv('climate_change_2.txt')\n",
    "\n",
    "# split the data into training data and test data\n",
    "data_split = 2006\n",
    "df1_train = df1[df1['Year'] <= data_split]\n",
    "df1_test = df1[df1['Year'] > data_split]\n",
    "df2_train = df2[df2['Year'] <= data_split]\n",
    "df2_test = df2[df2['Year'] > data_split]\n",
    "\n",
    "\n",
    "# distingush the data as label\n",
    "df1_train_temp = df1_train['Temp']\n",
    "df1_test_temp = df1_test['Temp']\n",
    "df2_train_temp = df2_train['Temp']\n",
    "df2_test_temp = df2_test['Temp']\n",
    "length_train1 = len(df1_train_temp)\n",
    "length_test1 = len(df1_test_temp)\n",
    "length_train2 = len(df2_train_temp)\n",
    "length_test2 = len(df2_test_temp)\n",
    "\n",
    "\n",
    "# distingush the data as feature\n",
    "df1_train_x = df1_train.loc[:,'MEI':'Aerosols']\n",
    "df1_train_x.insert(0, 'theta0', np.ones(length_train1))\n",
    "df1_test_x = df1_test.loc[:,'MEI':'Aerosols']\n",
    "df1_test_x.insert(0, 'theta0', np.ones(length_test1))\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "X_train, X_test, Y_train, Y_test = df1_train_x, df1_test_x, df1_train_temp, df1_test_temp\n",
    "pca = PCA(n_components=5)\n",
    "# 对模型进行训练\n",
    "pca.fit(X_train)\n",
    "# 返回降维后据\n",
    "X_train = pca.transform(X_train)\n",
    "\n",
    "# 使用返回后的数据用线性回归模型进行建模\n",
    "\n",
    "import statsmodels.api as sm\n",
    "ols = sm.OLS(Y_train, X_train).fit()\n",
    "ols.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 3 question 2:\n",
    "\n",
    "    When we use the PCA to contain only 5 variables, The answer is better. Because the most parameters are significant.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 4:\n",
    "    $$θj=θj-α\\frac{\\partial J(θ0, θ1)}{\\partial θj}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solve the minimum value of quadratic function:\n",
      "The solution is: theta [1.028, 1.983], f(theta) 2.00.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from random import random\n",
    "\n",
    "\n",
    "def gradientDescent(fn, partial_derivatives, n_variables, lr=0.1,\n",
    "                    max_iter=10000, tolerance=1e-5):\n",
    "    theta = [random() for _ in range(n_variables)]\n",
    "    y_cur = fn(*theta)\n",
    "    for i in range(max_iter):\n",
    "        # Calculate gradient of current theta.\n",
    "        gradient = [f(*theta) for f in partial_derivatives]\n",
    "        # Update the theta by the gradient.\n",
    "        for j in range(n_variables):\n",
    "            theta[j] -= gradient[j] * lr\n",
    "        # Check if converged or not.\n",
    "        y_cur, y_pre = fn(*theta), y_cur\n",
    "        if abs(y_pre - y_cur) < tolerance:\n",
    "            break\n",
    "    return theta, y_cur\n",
    "\n",
    "def f(x, y):\n",
    "    return (x + y - 3) ** 2 + (x + 2 * y - 5) ** 2 + 2\n",
    "\n",
    "\n",
    "def df_dx(x, y):\n",
    "    return 2 * (x + y - 3) + 2 * (x + 2 * y - 5)\n",
    "\n",
    "\n",
    "def df_dy(x, y):\n",
    "    return 2 * (x + y - 3) + 4 * (x + 2 * y - 5)\n",
    "\n",
    "def main():\n",
    "    print(\"Solve the minimum value of quadratic function:\")\n",
    "    n_variables = 2\n",
    "    theta, f_theta = gradientDescent(f, [df_dx, df_dy], n_variables)\n",
    "    theta = [round(x, 3) for x in theta]\n",
    "    print(\"The solution is: theta %s, f(theta) %.2f.\\n\" % (theta, f_theta))\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
